{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0105c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Multiple_Linear_Regression():   \n",
    "    def __init__ (self):\n",
    "        self.theta=np.zeros(int(np.random.random()),float)[:,np.newaxis]; \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        '''\n",
    "        Fit data to the model based on the matrix approach to Linear Regression. Actual magic happens here!  \n",
    "        \n",
    "        PARAMETERS:\n",
    "        X_train (numpy.ndarray): Independent variables train data.\n",
    "        y_train (numpy.ndarray): Dependent variable of train data.\n",
    "\n",
    "        RETURNS:\n",
    "        None\n",
    "        '''\n",
    "        X_b = np.c_[np.ones(len(X_train)), X_train] \n",
    "        theta_bst = np.linalg.pinv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)\n",
    "        self.theta = theta_bst\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        Fucntion to predict on new data.\n",
    "        \n",
    "        PARAMETERS:\n",
    "        X_test (numpy.ndarray): Independent variables data.\n",
    "\n",
    "        RETURNS:\n",
    "        y_predict (numpy.ndarray): Predicted dependent variable.\n",
    "        '''\n",
    "        X_test = np.c_[np.ones((len(X_test), 1)), X_test]\n",
    "        y_predict = np.dot(X_test, self.theta)\n",
    "        \n",
    "        return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52112b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self,X,Y): \n",
    "        ones=np.ones(X.shape)\n",
    "        X=np.append(ones,X,axis=1)\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "        self.m=X.shape[0]\n",
    "        self.n=X.shape[1]\n",
    "        self.theta=np.random.randn(X.shape[1])\n",
    "        \n",
    "    def computeCostFunction(self):\n",
    "        h=np.matmul(self.X,self.theta)\n",
    "        self.J=(1/(2*self.m))*np.sum((h-self.Y)**2)\n",
    "        return self.J\n",
    "    \n",
    "    def performGradientDescent(self,num_of_iter,alpha):\n",
    "        self.Cost_history=[]\n",
    "        self.theta_history=[]\n",
    "        for x in range(num_of_iter):\n",
    "            h=np.matmul(self.X,self.theta)\n",
    "            J=self.computeCostFunction()\n",
    "            self.Cost_history.append(J)\n",
    "            self.theta_history.append(self.theta)\n",
    "            temp=h-self.Y\n",
    "            self.theta=self.theta-(alpha/self.m)*(self.X.T.dot(temp))\n",
    "        return self.theta,self.Cost_history,self.theta_history\n",
    "            \n",
    "        \n",
    "    def predict(self,X_test,Y_test):\n",
    "        ones=np.ones(X_test.shape)\n",
    "        X_test=np.append(ones,X_test,axis=1)\n",
    "        self.Y_pred=np.matmul(X_test,self.theta)\n",
    "        self.error_percentage=(abs(self.Y_pred-Y_test)/Y_test)*100\n",
    "        return self.Y_pred,self.error_percentage\n",
    "    \n",
    "    def predictUsingNormalEquation(self,X_test,Y_test):\n",
    "        ones=np.ones(X_test.shape)\n",
    "        X_test=np.append(ones,X_test,axis=1)\n",
    "        inv=np.linalg.inv(np.matmul(self.X.T,self.X))\n",
    "        self.w=np.matmul(np.matmul(inv,self.X.T),self.Y)\n",
    "        y_pred=np.matmul(X_test,self.w)\n",
    "        return y_pred,(abs(Y_test-y_pred)/Y_test)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
